"""
Trade Log Analyzer â€” äº¤æ˜“æ—¥å¿—ç¦»çº¿åˆ†æå·¥å…·

ä» TradeLogger äº§ç”Ÿçš„ SQLite æ•°æ®åº“ä¸­åŠ è½½å†å²äº¤æ˜“è®°å½•ï¼Œ
ç”Ÿæˆç­–ç•¥ä¼˜åŒ–æ‰€éœ€çš„ç»Ÿè®¡åˆ†æã€‚

ç”¨æ³•:
    python scripts/analyze_trade_logs.py                    # åˆ†ææœ€è¿‘ä¸€æ¬¡è¿è¡Œ
    python scripts/analyze_trade_logs.py --run-id <id>      # åˆ†ææŒ‡å®šè¿è¡Œ
    python scripts/analyze_trade_logs.py --list              # åˆ—å‡ºæ‰€æœ‰è¿è¡Œè®°å½•
    python scripts/analyze_trade_logs.py --all               # åˆ†ææ‰€æœ‰è¿è¡Œ
    python scripts/analyze_trade_logs.py --last 5            # åˆ†ææœ€è¿‘ 5 æ¬¡è¿è¡Œ
    python scripts/analyze_trade_logs.py --export csv        # å¯¼å‡º CSV
"""

from __future__ import annotations

import argparse
import json
import sqlite3
import sys
from pathlib import Path

import pandas as pd

DB_PATH = Path("data/trade_logs.db")


def get_conn(db_path: Path = DB_PATH) -> sqlite3.Connection:
    if not db_path.exists():
        print(f"é”™è¯¯: æ•°æ®åº“ä¸å­˜åœ¨ â€” {db_path}")
        print("è¯·å…ˆè¿è¡Œ paper æˆ– live æ¨¡å¼ä»¥äº§ç”Ÿäº¤æ˜“æ—¥å¿—ã€‚")
        sys.exit(1)
    conn = sqlite3.connect(str(db_path))
    conn.row_factory = sqlite3.Row
    return conn


# ================================================================
#  åˆ—å‡ºè¿è¡Œè®°å½•
# ================================================================

def list_runs(conn: sqlite3.Connection, limit: int = 20) -> pd.DataFrame:
    df = pd.read_sql_query(
        "SELECT run_id, mode, strategy, "
        "datetime(start_time, 'unixepoch', 'localtime') as start, "
        "datetime(end_time, 'unixepoch', 'localtime') as end, "
        "total_orders, total_fills, total_settlements, "
        "win_count, loss_count, "
        "printf('%.1f%%', win_rate * 100) as win_rate, "
        "printf('%.4f', total_pnl) as pnl, "
        "status "
        "FROM runs ORDER BY start_time DESC LIMIT ?",
        conn,
        params=(limit,),
    )
    return df


# ================================================================
#  å•æ¬¡è¿è¡Œåˆ†æ
# ================================================================

def analyze_run(conn: sqlite3.Connection, run_id: str) -> None:
    """è¯¦ç»†åˆ†æä¸€æ¬¡è¿è¡Œçš„äº¤æ˜“æ—¥å¿—ã€‚"""
    # â”€â”€ è¿è¡Œæ‘˜è¦ â”€â”€
    run = conn.execute(
        "SELECT * FROM runs WHERE run_id = ?", (run_id,)
    ).fetchone()
    if not run:
        print(f"è¿è¡Œè®°å½•ä¸å­˜åœ¨: {run_id}")
        return

    print("=" * 70)
    print(f"  è¿è¡Œ ID:    {run['run_id']}")
    print(f"  æ¨¡å¼:       {run['mode']}")
    print(f"  ç­–ç•¥:       {run['strategy']}")
    print(f"  çŠ¶æ€:       {run['status']}")
    if run['start_time']:
        import datetime
        start = datetime.datetime.fromtimestamp(run['start_time'])
        print(f"  å¼€å§‹æ—¶é—´:   {start.strftime('%Y-%m-%d %H:%M:%S')}")
    if run['end_time']:
        end = datetime.datetime.fromtimestamp(run['end_time'])
        duration = run['end_time'] - run['start_time']
        print(f"  ç»“æŸæ—¶é—´:   {end.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"  è¿è¡Œæ—¶é•¿:   {duration:.0f}s ({duration/60:.1f}min)")
    print(f"  åˆå§‹ä½™é¢:   ${run['initial_balance']:.2f}" if run['initial_balance'] else "")
    print(f"  æœ€ç»ˆä½™é¢:   ${run['final_balance']:.2f}" if run['final_balance'] else "")
    print("=" * 70)

    # â”€â”€ è®¢å•ç»Ÿè®¡ â”€â”€
    orders_df = pd.read_sql_query(
        "SELECT * FROM order_logs WHERE run_id = ? ORDER BY timestamp",
        conn,
        params=(run_id,),
    )

    if orders_df.empty:
        print("\n  (æ— è®¢å•è®°å½•)")
    else:
        print(f"\nğŸ“Š è®¢å•ç»Ÿè®¡ ({len(orders_df)} ç¬”)")
        print("-" * 50)

        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        status_counts = orders_df["status"].value_counts()
        for status, count in status_counts.items():
            print(f"  {status}: {count}")

        # æŒ‰æ–¹å‘ç»Ÿè®¡
        filled = orders_df[orders_df["status"] == "filled"]
        if not filled.empty:
            print(f"\n  æˆäº¤è®¢å•: {len(filled)}")
            for direction in ["UP", "DOWN"]:
                d_orders = filled[filled["direction"] == direction]
                if not d_orders.empty:
                    avg_price = d_orders["filled_price"].mean()
                    total_shares = d_orders["filled_shares"].sum()
                    total_cost = (d_orders["filled_shares"] * d_orders["filled_price"]).sum()
                    print(
                        f"    {direction}: {len(d_orders)} ç¬” | "
                        f"å‡ä»·={avg_price:.4f} | "
                        f"shares={total_shares:.2f} | "
                        f"cost=${total_cost:.2f}"
                    )

            # ä¸‹å•æ—¶é—´åˆ†å¸ƒ
            print(f"\n  çª—å£å†…ä¸‹å•æ—¶é—´åˆ†å¸ƒ (secs_left):")
            secs = filled["window_seconds_left"]
            if secs.notna().any() and (secs > 0).any():
                valid = secs[secs > 0]
                print(f"    min={valid.min():.0f}s  max={valid.max():.0f}s  "
                      f"mean={valid.mean():.0f}s  std={valid.std():.1f}s")

            # åŠ¨é‡åˆ†å¸ƒ
            print(f"\n  åŠ¨é‡åˆ†å¸ƒ:")
            mom = filled["momentum"]
            if mom.notna().any():
                print(f"    min={mom.min():.2f}  max={mom.max():.2f}  "
                      f"mean={mom.mean():.2f}  std={mom.std():.2f}")

            # Edge åˆ†å¸ƒ
            print(f"\n  Edge åˆ†å¸ƒ:")
            edg = filled["edge"]
            if edg.notna().any():
                print(f"    min={edg.min():.4f}  max={edg.max():.4f}  "
                      f"mean={edg.mean():.4f}")

            # BTC ä»·æ ¼èŒƒå›´
            print(f"\n  BTC ä»·æ ¼èŒƒå›´:")
            btc = filled["btc_price"]
            if btc.notna().any() and (btc > 0).any():
                valid_btc = btc[btc > 0]
                print(f"    min=${valid_btc.min():,.2f}  max=${valid_btc.max():,.2f}")

    # â”€â”€ ç»“ç®—ç»Ÿè®¡ â”€â”€
    settle_df = pd.read_sql_query(
        "SELECT * FROM settlement_logs WHERE run_id = ? ORDER BY timestamp",
        conn,
        params=(run_id,),
    )

    if settle_df.empty:
        print("\n  (æ— ç»“ç®—è®°å½•)")
    else:
        print(f"\nğŸ“Š ç»“ç®—ç»Ÿè®¡ ({len(settle_df)} ä¸ªçª—å£)")
        print("-" * 50)

        wins = settle_df[settle_df["result"] == "WIN"]
        losses = settle_df[settle_df["result"] == "LOSE"]
        print(f"  èƒœ: {len(wins)}  è´Ÿ: {len(losses)}  "
              f"èƒœç‡: {len(wins)/len(settle_df)*100:.1f}%")

        total_pnl = settle_df["net_pnl"].sum()
        avg_pnl = settle_df["net_pnl"].mean()
        print(f"  æ€» PnL: {total_pnl:+.4f} USDC")
        print(f"  å¹³å‡ PnL/çª—å£: {avg_pnl:+.4f} USDC")

        if not wins.empty:
            avg_win = wins["net_pnl"].mean()
            print(f"  å¹³å‡ç›ˆåˆ©: {avg_win:+.4f} USDC")
        if not losses.empty:
            avg_loss = losses["net_pnl"].mean()
            print(f"  å¹³å‡äºæŸ: {avg_loss:+.4f} USDC")

        # Edge åˆ†æ
        print(f"\n  å®é™… Edge åˆ†æ:")
        edge = settle_df["actual_edge"]
        if edge.notna().any():
            print(f"    å‡å€¼: {edge.mean():.4f}  ä¸­ä½æ•°: {edge.median():.4f}")
            print(f"    æ­£Edge: {(edge > 0).sum()}/{len(edge)}  "
                  f"({(edge > 0).mean()*100:.1f}%)")

        # Gap åˆ†æ
        print(f"\n  Gap (UP-DN shares å·®å¼‚) åˆ†æ:")
        gap = settle_df["gap_shares"]
        gap_pct = settle_df["gap_pct"]
        if gap.notna().any():
            print(f"    shares: mean={gap.mean():+.2f}  std={gap.std():.2f}")
            print(f"    pct:    mean={gap_pct.mean():.1f}%  max={gap_pct.max():.1f}%")

        # äºæŸçª—å£ç‰¹å¾åˆ†æ
        if not losses.empty and len(losses) >= 2:
            print(f"\n  äºæŸçª—å£ç‰¹å¾:")
            print(f"    å¹³å‡ entries: {losses['entries'].mean():.1f}")
            print(f"    å¹³å‡ gap:     {losses['gap_pct'].mean():.1f}%")
            print(f"    å¹³å‡ edge:    {losses['actual_edge'].mean():.4f}")

        # PnL æ›²çº¿
        print(f"\n  PnL è½¨è¿¹:")
        cumsum = settle_df["net_pnl"].cumsum()
        peak = cumsum.cummax()
        drawdown = cumsum - peak
        max_dd = drawdown.min()
        print(f"    æœ€å¤§å›æ’¤: {max_dd:+.4f} USDC")
        print(f"    æœ€é«˜ç‚¹:   {peak.max():+.4f} USDC")

    # â”€â”€ ä¿¡å·ç»Ÿè®¡ â”€â”€
    signal_df = pd.read_sql_query(
        "SELECT * FROM signal_logs WHERE run_id = ? ORDER BY timestamp",
        conn,
        params=(run_id,),
    )

    if not signal_df.empty:
        print(f"\nğŸ“Š ä¿¡å·ç»Ÿè®¡ ({len(signal_df)} ä¸ª)")
        print("-" * 50)
        exec_count = signal_df["executed"].sum()
        print(f"  å·²æ‰§è¡Œ: {exec_count}  è·³è¿‡: {len(signal_df) - exec_count}")
        if "momentum" in signal_df.columns:
            mom = signal_df["momentum"]
            if mom.notna().any():
                print(f"  ä¿¡å·åŠ¨é‡: mean={mom.mean():.2f}  std={mom.std():.2f}")


# ================================================================
#  å¤šæ¬¡è¿è¡Œå¯¹æ¯”
# ================================================================

def compare_runs(conn: sqlite3.Connection, run_ids: list[str]) -> None:
    """å¯¹æ¯”å¤šæ¬¡è¿è¡Œçš„å…³é”®æŒ‡æ ‡ã€‚"""
    rows = []
    for rid in run_ids:
        run = conn.execute(
            "SELECT * FROM runs WHERE run_id = ?", (rid,)
        ).fetchone()
        if not run:
            continue

        settle_df = pd.read_sql_query(
            "SELECT net_pnl, actual_edge, gap_pct, entries "
            "FROM settlement_logs WHERE run_id = ?",
            conn,
            params=(rid,),
        )

        duration = 0
        if run['end_time'] and run['start_time']:
            duration = run['end_time'] - run['start_time']

        rows.append({
            "run_id": rid[:30],
            "mode": run["mode"],
            "strategy": (run["strategy"] or "")[:20],
            "duration_min": round(duration / 60, 1),
            "orders": run["total_orders"],
            "fills": run["total_fills"],
            "settlements": run["total_settlements"],
            "win_rate": f"{(run['win_rate'] or 0) * 100:.1f}%",
            "total_pnl": round(run["total_pnl"] or 0, 4),
            "avg_pnl": round(settle_df["net_pnl"].mean(), 4) if not settle_df.empty else 0,
            "avg_edge": round(settle_df["actual_edge"].mean(), 4) if not settle_df.empty else 0,
            "avg_gap%": round(settle_df["gap_pct"].mean(), 1) if not settle_df.empty else 0,
        })

    if rows:
        df = pd.DataFrame(rows)
        print("\nğŸ“Š è¿è¡Œå¯¹æ¯”")
        print("=" * 100)
        print(df.to_string(index=False))
    else:
        print("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è¿è¡Œè®°å½•")


# ================================================================
#  å¯¼å‡º
# ================================================================

def export_run(conn: sqlite3.Connection, run_id: str, fmt: str = "csv") -> None:
    """å¯¼å‡ºæŒ‡å®šè¿è¡Œçš„æ•°æ®ã€‚"""
    export_dir = Path("data/trade_logs/exports")
    export_dir.mkdir(parents=True, exist_ok=True)

    for table in ["order_logs", "settlement_logs", "signal_logs"]:
        df = pd.read_sql_query(
            f"SELECT * FROM {table} WHERE run_id = ? ORDER BY timestamp",
            conn,
            params=(run_id,),
        )
        if df.empty:
            continue

        if fmt == "csv":
            path = export_dir / f"{run_id}_{table}.csv"
            df.to_csv(path, index=False)
        elif fmt == "parquet":
            path = export_dir / f"{run_id}_{table}.parquet"
            df.to_parquet(path, index=False)
        else:
            path = export_dir / f"{run_id}_{table}.json"
            df.to_json(path, orient="records", lines=True)

        print(f"  å·²å¯¼å‡º: {path}")


# ================================================================
#  JSONL åŠ è½½è¾…åŠ©
# ================================================================

def load_jsonl(path: str | Path) -> pd.DataFrame:
    """åŠ è½½ JSONL æ–‡ä»¶ä¸º DataFrame (ç”¨äºæ›´ç»†ç²’åº¦åˆ†æ)ã€‚"""
    records = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                records.append(json.loads(line))
    return pd.DataFrame(records)


# ================================================================
#  CLI
# ================================================================

def main():
    parser = argparse.ArgumentParser(
        description="äº¤æ˜“æ—¥å¿—åˆ†æå·¥å…· â€” åˆ†æ paper/live è¿è¡Œè®°å½•ä»¥ä¼˜åŒ–ç­–ç•¥",
    )
    parser.add_argument("--db", type=str, default="data/trade_logs.db",
                        help="æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--list", action="store_true",
                        help="åˆ—å‡ºæ‰€æœ‰è¿è¡Œè®°å½•")
    parser.add_argument("--run-id", type=str, default="",
                        help="åˆ†ææŒ‡å®šè¿è¡Œ ID")
    parser.add_argument("--all", action="store_true",
                        help="åˆ†ææ‰€æœ‰è¿è¡Œ")
    parser.add_argument("--last", type=int, default=0,
                        help="åˆ†æ/å¯¹æ¯”æœ€è¿‘ N æ¬¡è¿è¡Œ")
    parser.add_argument("--export", type=str, choices=["csv", "parquet", "json"],
                        help="å¯¼å‡ºè¿è¡Œæ•°æ®")

    args = parser.parse_args()
    conn = get_conn(Path(args.db))

    if args.list:
        df = list_runs(conn, limit=50)
        if df.empty:
            print("æš‚æ— è¿è¡Œè®°å½•ã€‚")
        else:
            print("\nğŸ“‹ è¿è¡Œè®°å½•")
            print("=" * 120)
            print(df.to_string(index=False))
        conn.close()
        return

    if args.run_id:
        if args.export:
            export_run(conn, args.run_id, args.export)
        else:
            analyze_run(conn, args.run_id)
        conn.close()
        return

    if args.last > 0:
        runs = conn.execute(
            "SELECT run_id FROM runs ORDER BY start_time DESC LIMIT ?",
            (args.last,),
        ).fetchall()
        run_ids = [r["run_id"] for r in runs]
        if len(run_ids) == 1:
            analyze_run(conn, run_ids[0])
        elif len(run_ids) > 1:
            compare_runs(conn, run_ids)
            print("\n" + "=" * 70)
            print("è¦æŸ¥çœ‹å•æ¬¡è¿è¡Œè¯¦æƒ…, è¯·ä½¿ç”¨: --run-id <id>")
        else:
            print("æš‚æ— è¿è¡Œè®°å½•ã€‚")
        conn.close()
        return

    if args.all:
        runs = conn.execute(
            "SELECT run_id FROM runs ORDER BY start_time DESC"
        ).fetchall()
        run_ids = [r["run_id"] for r in runs]
        if run_ids:
            compare_runs(conn, run_ids)
        else:
            print("æš‚æ— è¿è¡Œè®°å½•ã€‚")
        conn.close()
        return

    # é»˜è®¤: åˆ†ææœ€è¿‘ä¸€æ¬¡è¿è¡Œ
    latest = conn.execute(
        "SELECT run_id FROM runs ORDER BY start_time DESC LIMIT 1"
    ).fetchone()
    if latest:
        run_id = latest["run_id"]
        if args.export:
            export_run(conn, run_id, args.export)
        else:
            analyze_run(conn, run_id)
    else:
        print("æš‚æ— è¿è¡Œè®°å½•ã€‚è¯·å…ˆè¿è¡Œ paper æˆ– live æ¨¡å¼ã€‚")

    conn.close()


if __name__ == "__main__":
    main()
